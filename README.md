# multi-class-text-classification
This project uses BERT for multi-class news classification based on titles and descriptions. It includes data cleaning, tokenization, dataset preparation, model fine-tuning, and evaluation setup. Ideal for understanding end-to-end NLP pipelines with Hugging Face Transformers.
